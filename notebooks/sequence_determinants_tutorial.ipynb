{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding STk vs. Tk sequence determinants\n",
    "\n",
    "In this example, we'll tackle a problem of multiple sequence alignemnt (MSA)\n",
    "sequences' classification.\n",
    "\n",
    "Protein kinases, or phosphate transferases, are regulatory enzymes ubiquitous\n",
    "across all major known taxae. They catalyze transferring of phosphate moieties\n",
    "from an ATP molecule to the carboxylic group of an amino acid residue. This\n",
    "changes physico-chemical properties of a target protein altering it's overall\n",
    "behaviour and functionality. Thus, they act as molecular controllers, deeply\n",
    "embedded into regulating mechanisms governing complex cellular machinery.\n",
    "\n",
    "Over the course of evolution, along with substrate specificity, PKs developed\n",
    "a preference towards certain amino acid residues (Fig. 1). The principal group\n",
    "of PKs that likely appeared initially were PKs transferring phosphate to serine\n",
    "and threonine residues (STk). Later, another group emerged, specializing towards\n",
    "the tyrosine residue (Tk).\n",
    "\n",
    "| ![Phosphorylation](../fig/Phosphorylation.pdf \"Phosphorylation reaction\") |\n",
    "|:--:|\n",
    "| <b> Fig. 1. Phosphorylation of Ser/Thr and Tyr. Notice the dissimilarities between these two groups </b>|\n",
    "\n",
    "What could be the sequence differences enabling such a specialization?\n",
    "Could we find them using features selection machinery?\n",
    "\n",
    "In 1994, Juswinder performed a conservation-based analysis of STk and Tk\n",
    "sequences.\n",
    "He discovered several MSA positions that, as structural evidence suggests, expliot\n",
    "physico-chemical differences (e.g., volume) between Ser/Thr and Tyr.\n",
    "For this, he used a scoring function that would spot positions with substantial\n",
    "but different conservation between STk and Tk sequences in the same multiple\n",
    "sequence alignment.\n",
    "\n",
    "| ![PK domains alignment](../fig/juswinderA.png \"Juswinder et al. MSA (A)\") |\n",
    "|:--:|\n",
    "| <b> Fig. 2. Positions of STk ad Tk sub-alignment (note 201 and 203) </b>|\n",
    "\n",
    "| ![PK domains alignment](../fig/juswinderB.png \"Juswinder et al. MSA (B)\") |\n",
    "|:--:|\n",
    "| <b> Fig. 2. Positions of STk and TK sub-alignment part2 (note 168 and 170) </b>|\n",
    "\n",
    "Here, we'll attempt to recover positions highlighted by Juswinder on a larger\n",
    "MSA built from reviewed [UniProt](https://www.uniprot.org) sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install lXtractor eBoruta ipywidgets xgboost optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re\n",
    "from collections import Counter\n",
    "from io import StringIO, BytesIO\n",
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "from lXtractor.core.chain import ChainSequence, ChainList\n",
    "from lXtractor.ext.hmm import PyHMMer\n",
    "from lXtractor.util.io import fetch_text\n",
    "from lXtractor.variables.calculator import GenericCalculator\n",
    "from lXtractor.variables.manager import Manager\n",
    "from lXtractor.variables.sequential import PFP\n",
    "from more_itertools import consume"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.1 Download and parse initial sequences and profile"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The UniProt link is generated from the search API.\n",
    "We are taking all reviewed proteins (Swiss-Prot database) belonging to the PK superfamily.\n",
    "\n",
    "Link to Pfam points to the _PF00069_ -- a protein kinase domain HMM profile."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LINK_UNIPROT = \"https://rest.uniprot.org/uniprotkb/stream?fields=accession%2Cid%2Csequence%2Cft_domain%2Cprotein_families&format=tsv&query=%28%28family%3A%22protein%20kinase%20superfamily%22%29%29%20AND%20%28reviewed%3Atrue%29\"\n",
    "LINK_PFAM = 'https://www.ebi.ac.uk/interpro/wwwapi//entry/pfam/PF00069?annotation=hmm'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_up = pd.read_csv(StringIO(fetch_text(LINK_UNIPROT)), sep='\\t')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_up.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize profile as `PyHMMer` object internally interfacing homonimous library.\n",
    "`PyHMMer` is an annotator class, annotating (subsetting) `ChainSequence`s using\n",
    "HMM-derived domain boundaries."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prof = PyHMMer(BytesIO(gzip.decompress(\n",
    "    fetch_text(LINK_PFAM, decode=False)\n",
    ")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Convert sequences\n",
    "\n",
    "Initialize `ChainSequence`s and wrap them into the `ChainList`.\n",
    "The latter simplifies working with a group of `Chain*`-type objects.\n",
    "To learn more, check [lXtractor documentation](https://lxtractor.readthedocs.io/en/latest/)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def wrap_into_chain_seq(row):\n",
    "    \"\"\"\n",
    "    :param row: DataFrame row.\n",
    "    :return: chain sequence using \"Sequence\" field to obtain a full\n",
    "        protein sequence and \"Entry Name\" for its name.\n",
    "    \"\"\"\n",
    "    fam_df = row['Protein families']\n",
    "    family = 'other'\n",
    "    if 'protein kinase family' in fam_df:\n",
    "        if 'Ser/Thr' in fam_df:\n",
    "            family = 'STk'\n",
    "        elif 'Tyr' in fam_df:\n",
    "            family = 'Tk'\n",
    "\n",
    "    return ChainSequence.from_string(\n",
    "        row['Sequence'], name=row['Entry Name'], meta={'Family': family}\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chains = ChainList(\n",
    "    wrap_into_chain_seq(r) for _, r in df_up.iterrows()\n",
    ")\n",
    "Counter(c.meta['Family'] for c in chains)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Select only those whose family was classified as STk or Tk."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chains = chains.filter(lambda x: x.meta['Family'] != 'other')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below, alignment-extracted boundaries are used to create a \"child\"\n",
    "subsequence for each `ChainSequence` in `chains`. We also specify acceptance\n",
    "criteria: minimum length of extracted domain, minimum coverage, i.e., how many\n",
    "HMM positions were covered by the extracted sequence, and minimum bit score\n",
    "(which is a bit higher than the profile's own threshold; just to be safe)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "consume(prof.annotate(\n",
    "    chains, new_map_name='PK', min_size=150, min_cov_hmm=0.7, min_score=50\n",
    "));"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(chains), len(chains.collapse_children())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We observe that the final number of chains with annotated domains under the\n",
    "filtering criteria specified above differs from the initial number of chains.\n",
    "UniProt obtains PK domain annotations using a different profile using `ProSite`\n",
    "software. Thus, the filtering criteria are essentially sensitivity tweaks."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "chains = chains.filter(lambda x: len(x.children) > 0)\n",
    "len(chains), Counter(c.meta['Family'] for c in chains)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Prepare encoded dataset\n",
    "\n",
    "We encode the alignment using the ProtFP embeddings derived from the PCA of\n",
    "the AAIndex database. Thus, they encapsulate many physico-chemical properties\n",
    "in several compact dimensions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The number of PCA components to take."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_COMP = 3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define variables -- `N_COMP` PCA components for each profile position.\n",
    "`lXtractor` is shipped with values already and the \"calculation\" of variables\n",
    "below is simply accessing the table values for each valid residue. By default,\n",
    "`NaN` used as a placeholder for empty values (gaps in the sequence-to-profile\n",
    "alignment)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "variables = list(chain.from_iterable(\n",
    "    (PFP(pos, i) for i in range(1, N_COMP + 1)) for pos in range(1, prof.hmm.M + 1)\n",
    "))\n",
    "len(variables)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "manager = Manager(verbose=True)\n",
    "calculator = GenericCalculator()  # You may increase the number of processes here.\n",
    "domains = chains.collapse_children()\n",
    "df = manager.aggregate_from_it(\n",
    "    # `calculate` returns a generator of the calculation results.\n",
    "    # We immediately aggregate the results into a single table.\n",
    "    manager.calculate(domains, variables, calculator, map_name='PK')\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, incorporate labels for STk (0) and Tk (1) domain sequences."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cls_map = {'STk': 0, 'Tk': 1}\n",
    "id2cls = {s.id: cls_map[s.parent.meta['Family']] for s in domains}\n",
    "df['IsTk'] = df['ObjectID'].map(id2cls)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv('./fs.tmp.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('./fs.tmp.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 Setup\n",
    "\n",
    "For convenience, we'll define several helper functions and a `Dataset` dataclass\n",
    "holding the full dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "from eBoruta import eBoruta\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Dataset:\n",
    "    df: pd.DataFrame\n",
    "    x_names: list[str]\n",
    "    y_name: str\n",
    "\n",
    "    @property\n",
    "    def x(self) -> pd.DataFrame:\n",
    "        return self.df[self.x_names]\n",
    "\n",
    "    @property\n",
    "    def y(self) -> pd.Series:\n",
    "        return self.df[self.y_name]\n",
    "\n",
    "\n",
    "def sel_by_idx(ds, idx):\n",
    "    \"\"\"\n",
    "    :param ds: Dataset.\n",
    "    :param idx: Array of numeric indices.\n",
    "    :return: New `Dataset` instance with the same variables\n",
    "        and rows selected by `idx`.\n",
    "    \"\"\"\n",
    "    return Dataset(ds.df.iloc[idx], ds.x_names, ds.y_name)\n",
    "\n",
    "\n",
    "def score(ds, model, score_fn=f1_score):\n",
    "    \"\"\"\n",
    "    F1-score for the classifier model.\n",
    "    \"\"\"\n",
    "    return score_fn(ds.y.values, model.predict(ds.x))\n",
    "\n",
    "\n",
    "def cv(ds, model, n=10, score_fn=f1_score, agg_fn=np.mean):\n",
    "    \"\"\"\n",
    "    Cross validate the model returning the aggregated score.\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    splitter = StratifiedShuffleSplit(n_splits=n)\n",
    "    for train_idx, test_idx in splitter.split(ds.x, ds.y):\n",
    "        ds_train = sel_by_idx(ds, train_idx)\n",
    "        ds_test = sel_by_idx(ds, test_idx)\n",
    "        _model = model.__class__(**model.get_params())\n",
    "        _model.fit(ds_train.x, ds_train.y)\n",
    "        scores.append(score(ds_test, _model, score_fn))\n",
    "    return agg_fn(scores)\n",
    "\n",
    "# def plot_imp_history(df_history: pd.DataFrame):\n",
    "#     sns.lineplot(x='Step', y='Importance', hue='Feature', data=df_history)\n",
    "#     sns.lineplot(x='Step', y='Threshold', data=df_history, linestyle='--', linewidth=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# How many top features to review?\n",
    "TOP_N = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = Dataset(df, [c for c in df.columns if 'PFP' in c], 'IsTk')\n",
    "classifier = XGBClassifier(n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2 Cross-validate the initial model\n",
    "\n",
    "Before attempting anything, let's just first cross-validating the model on the\n",
    "full dataset. We should obtain a decent result by itself. It's good practice\n",
    "to test whether subsequent feature selection deteriorates this baseline result."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv(dataset, classifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.3 Select Features\n",
    "\n",
    "Run the feature selection itself. We'll keep the default parameters and a large\n",
    "number of iterations to obtain final decisions for each feature. Then we'll rank\n",
    "features and select top N features to analyze further."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "boruta = eBoruta(n_iter=100, shap_approximate=False, shap_tree=True)\n",
    "boruta.fit(dataset.x, dataset.y, model=classifier, verbose=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll rank the accepted features. Ranking means refitting the model using\n",
    "supplied (here, accepted) features, calculating and sorting by feature importance\n",
    "values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ranks = boruta.rank(features=boruta.features_.accepted, fit=True)\n",
    "ranks.head(TOP_N)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "top_n_features = ranks.Feature[:TOP_N].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds_sel = Dataset(\n",
    "    df[['ObjectID', *top_n_features, dataset.y_name]], top_n_features, dataset.y_name\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.4 CV score using selected features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we'll use the dataset with accepted features to cross-validate the model.\n",
    "Indeed, the CV score is very similar to the previously obtained on a full dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv(ds_sel, classifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Interpret the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "POS_PATTERN = re.compile('p=(\\d+)')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ds_sample = ds_sel.df.groupby('IsTk').sample(30)\n",
    "positions = sorted(\n",
    "    {int(POS_PATTERN.findall(c)[0]) for c in ds_sample.columns if 'p=' in c}\n",
    ")\n",
    "positions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_positions(c: ChainSequence) -> str:\n",
    "    m = c.get_map('PK')\n",
    "    mapped = map(\n",
    "        lambda x: x if x == '-' else x.seq1,\n",
    "        (m.get(p, '-') for p in positions))\n",
    "    return \"\".join(mapped)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_chains = [domains[x].pop() for x in ds_sample['ObjectID']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "positions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seqs = map(extract_positions, sample_chains)\n",
    "\n",
    "for is_tk, seq in zip(ds_sample.IsTk, seqs):\n",
    "    print(seq, is_tk)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "One may notice from above the following correspondence between Figures 2 and 3\n",
    "and conservation patterns observed above. Firstly, position 125 clearly\n",
    "corresponds to position 168 on Fig. 3, with conserved K in STk and A/R in Tk.\n",
    "Furthermore, position 127 corresponds to 170 on Fig. 3, with conserved R in Tk.\n",
    "Moving on, position 162 corresponds to 203 in Fig. 2, with conserved K and R in\n",
    "Tk.\n",
    "\n",
    "Thus, feature selection managed to retrieve features whose conservation patterns\n",
    "differed between STk and Tk. Moreover, selected feature pertain to positions\n",
    "implicated as critical for the STk/Tk functional differences by a research\n",
    "paper; thus, clearly relevant."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
