{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/edikedik/eBoruta/blob/master/notebooks/demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Boruta` usage demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install seaborn xgboost scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import typing as t\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import shap\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from eBoruta import eBoruta, TrialData, Features, Dataset, setup_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_imp_history(df_history: pd.DataFrame):\n",
    "    sns.lineplot(x='Step', y='Importance', hue='Feature', data=df_history)\n",
    "    sns.lineplot(x='Step', y='Threshold', data=df_history, linestyle='--', linewidth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage\n",
    "\n",
    "Single objective, `RandomForestClassifier`, default params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x, y = make_classification(100, 10, n_informative=2)\n",
    "boruta = eBoruta()\n",
    "boruta.fit(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase verbosity\n",
    "\n",
    "Turn on logging to get a glimpse on what's going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "LOGGER = setup_logger(stdout_level=logging.DEBUG, logger=logging.getLogger('eBoruta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boruta = eBoruta(verbose=2)\n",
    "boruta.fit(x, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access features and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "features = boruta.features_\n",
    "features.accepted, features.rejected, features.tentative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = features.history\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `n_rows = n_steps * n_features`. `df.dropna()` cleans the table giving access to the last step for a feature where it was used.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.dropna().groupby('Feature').tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Query history to inspect the selection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[df['Feature'] == '7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One can use history to produce plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plot_imp_history(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?eBoruta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lower percentile threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "boruta = eBoruta(percentile=70).fit(x, y)\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lower p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta = eBoruta(pvalue=0.005).fit(x, y)\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Apply rough fix\n",
    "\n",
    "This won't overwrite existing `boruta.features_` but will return a new `Features` instance. In the latter, the history will remain unchanged, but the `accepted`, `rejected`, and `tentative` attributes will be modified accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fs = boruta.rough_fix(n_last_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fs.accepted, fs.rejected, fs.tentative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta = eBoruta(test_size=0.3, test_stratify=True).fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Advanced usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different models\n",
    "\n",
    "In principle, the model can be __any__ callable defining a `fit` method -- classifier or regressor -- as long as the importance calculation is defined.\n",
    "Note that one can define the latter manually (see below).\n",
    "\n",
    "For instance, we'll use the `XGBClassifier` and `CatBoostClassifier` below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `XGBClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "boruta = eBoruta().fit(x, y, model=XGBClassifier(n_estimators=20, verbosity=0))\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `CatBoostClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# shap with `approximate` is not supported for catboost currently\n",
    "boruta = eBoruta().fit(x, y, model=CatBoostClassifier(iterations=20, verbose=False))\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom importance measure\n",
    "\n",
    "Any callable accepting an estimator or estimator together with the `TrialData` object and returning a numpy array with shape `(n_test_features, )` will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_imp(estimator):\n",
    "    # equivalent to the builtin importance getter\n",
    "    return estimator.feature_importances_\n",
    "\n",
    "boruta = eBoruta(importance_getter=get_imp)\n",
    "boruta.fit(x, y)\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_permutation_imp(estimator: t.Any, trial_data: TrialData) -> np.ndarray:\n",
    "    imp = permutation_importance(\n",
    "        estimator, trial_data.x_test, trial_data.y_test, \n",
    "        scoring='accuracy', n_jobs=-1\n",
    "    )\n",
    "    return np.array(imp['importances_mean'])\n",
    "\n",
    "# Let's also use a different estimator, just for the sake of it\n",
    "boruta = eBoruta(\n",
    "    importance_getter=get_permutation_imp\n",
    ").fit(\n",
    "    x, y, model=ExtraTreesClassifier(n_estimators=20)\n",
    ")\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-ensemble classifier with custom importance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "boruta = eBoruta(\n",
    "    importance_getter=get_permutation_imp\n",
    ").fit(\n",
    "    x, y, model=LogisticRegression()\n",
    ")\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple objectives\n",
    "\n",
    "Built-in approach is basically averaging importance of each feature per objective.\n",
    "One can define a different aggregation strategy via custom importance getter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y2 = np.array([[y_, y_] for y_ in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using built-in shap importance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "boruta = eBoruta().fit(x, y2)\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using `feature_importances_` attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Using shap importance\n",
    "boruta = eBoruta(shap_tree=False).fit(x, y2)\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using custom importance evaluation\n",
    "\n",
    "Use-case: different aggregation strategy for multiple objectives. Below we'll use maximum of importances for a feature across objectives instead of the default mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Using custom aggregation\n",
    "def get_imp(estimator, trial_data: TrialData):\n",
    "    # equivalent to the builtin importance getter\n",
    "    explainer = shap.explainers.Tree(estimator)\n",
    "    imp = explainer.shap_values(trial_data.x_test, approximate=False)\n",
    "    imp = np.max(np.vstack([np.abs(v).mean(0) for v in imp]), axis=0)\n",
    "    return imp\n",
    "\n",
    "\n",
    "boruta = eBoruta(importance_getter=get_imp).fit(x, y)\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using `Callback`s\n",
    "\n",
    "It can be any callable (including classes with mutable state), accepting and returning `(Estimator, Feature, Dataset, Trial)`.\n",
    "Check `callbacks` module for additional examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `CatBoostClassifier` with categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_catboost_categorical(\n",
    "    estimator: CatBoostClassifier, features: Features, \n",
    "    dataset: Dataset, trial_data: TrialData, **kwargs\n",
    "):\n",
    "    params = estimator.get_params()\n",
    "    params['cat_features'] = [c for c in trial_data.x_test.columns if 'cat' in c]\n",
    "    estimator = estimator.__class__(**params)\n",
    "    return estimator, features, dataset, trial_data, kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_cat = boruta.dataset_.x.copy()\n",
    "x_cat['1_cat'] = pd.Series(x_cat['1'].round(0).astype(int).astype('category'))\n",
    "\n",
    "boruta = eBoruta().fit(\n",
    "    x_cat, y, model=CatBoostClassifier(iterations=20, verbose=False),\n",
    "    callbacks_trial_start=[handle_catboost_categorical],\n",
    ")\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `CatBoostClassifier` with adjusted number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class AdjustIterations:\n",
    "    def __init__(self, min_iterations: int = 5):\n",
    "        self.min_iterations = min_iterations\n",
    "\n",
    "    def __call__(self, estimator: CatBoostClassifier, features: Features, dataset: Dataset, trial_data: TrialData, **kwargs):\n",
    "        num_features = trial_data.x_test.shape[1]\n",
    "        num_iterations = max([self.min_iterations, num_features // 2])\n",
    "        params = estimator.get_params()\n",
    "        params['iterations'] = num_iterations\n",
    "        estimator = estimator.__class__(**params)\n",
    "        print(f'Set the number of iterations to {estimator.get_param(\"iterations\")} (num_features={num_features})')\n",
    "        return estimator, features, dataset, trial_data, kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "boruta = eBoruta().fit(\n",
    "    x, y, model=CatBoostClassifier(iterations=20, verbose=False), \n",
    "    callbacks_trial_start=[AdjustIterations()]\n",
    ")\n",
    "plot_imp_history(boruta.features_.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
